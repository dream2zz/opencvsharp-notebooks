{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人脸识别\n",
    "===\n",
    "\n",
    "## Haar\n",
    "\n",
    "### 基本概念\n",
    "Haar级联分类器是由Paul Viola和Michael Jones在2001年提出的。它使用Haar特征和级联分类器来快速检测图像中的对象（如人脸）。\n",
    "\n",
    "### Haar特征\n",
    "Haar特征是一种简单的矩形特征，类似于Haar小波。常见的Haar特征包括边缘特征、线特征和四边形特征。每个特征由两个或多个矩形区域组成，通过计算这些区域的像素值之差来表示特征值。\n",
    "\n",
    "### 级联分类器\n",
    "级联分类器是一种分层的分类器结构。每一层都是一个弱分类器，只有当一个图像区域通过当前层的检测时，才会进入下一层进行更详细的检测。这种结构可以显著提高检测速度，因为大部分非目标区域会在前几层被快速排除。\n",
    "\n",
    "### 训练过程\n",
    "1. 收集正负样本：收集包含目标对象（如人脸）的正样本和不包含目标对象的负样本。\n",
    "2. 计算Haar特征：对样本图像计算大量的Haar特征。\n",
    "3. 训练弱分类器：使用AdaBoost算法训练多个弱分类器，每个弱分类器基于一个Haar特征。\n",
    "4. 构建级联分类器：将多个弱分类器按层次结构组合成一个级联分类器。\n",
    "\n",
    "### 使用方法\n",
    "在OpenCV中，可以使用CascadeClassifier类加载预训练的Haar级联分类器，并使用DetectMultiScale方法进行人脸检测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>OpenCvSharp4.Windows, 4.10.0.20240616</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: OpenCvSharp4.Windows\"\n",
    "using OpenCvSharp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var cascade = new CascadeClassifier(\"assets/haarcascade_frontalface_default.xml\");\n",
    "using (var src = new Mat(\"assets/faces.jpg\", ImreadModes.Color))\n",
    "using (var gray = new Mat())\n",
    "{\n",
    "    Mat result = src.Clone();\n",
    "    Cv2.CvtColor(src, gray, ColorConversionCodes.BGR2GRAY);\n",
    "\n",
    "    // Detect faces\n",
    "    Rect[] faces = cascade.DetectMultiScale(gray, 1.08, 2, HaarDetectionTypes.ScaleImage, new Size(30, 30));\n",
    "\n",
    "    // Render all detected faces\n",
    "    foreach (Rect face in faces)\n",
    "    {\n",
    "        var center = new Point\n",
    "        {\n",
    "            X = (int)(face.X + face.Width * 0.5),\n",
    "            Y = (int)(face.Y + face.Height * 0.5)\n",
    "        };\n",
    "        var axes = new Size\n",
    "        {\n",
    "            Width = (int)(face.Width * 0.5),\n",
    "            Height = (int)(face.Height * 0.5)\n",
    "        };\n",
    "        Cv2.Ellipse(result, center, axes, 0, 0, 360, new Scalar(255, 0, 255), 4);\n",
    "    }\n",
    "\n",
    "    Cv2.ImShow(\"Faces by Haar\", result);\n",
    "    Cv2.WaitKey(0);\n",
    "    Cv2.DestroyAllWindows();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBP\n",
    "\n",
    "### 基本概念\n",
    "LBP（局部二值模式）是一种纹理描述符，由Timo Ojala等人在1994年提出。LBP级联分类器使用LBP特征和级联分类器来检测图像中的对象。\n",
    "\n",
    "### LBP特征\n",
    "LBP特征通过比较像素与其邻域像素的灰度值来生成二进制模式。具体步骤如下：\n",
    "1.\t选择中心像素：选择一个像素作为中心像素。\n",
    "2.\t比较邻域像素：将中心像素与其邻域像素进行比较，如果邻域像素的灰度值大于或等于中心像素，则该位置记为1，否则记为0。\n",
    "3.\t生成二进制模式：将比较结果按顺序排列，生成一个二进制数。\n",
    "\n",
    "### 级联分类器\n",
    "与Haar级联分类器类似，LBP级联分类器也使用分层的分类器结构。每一层都是一个弱分类器，只有当一个图像区域通过当前层的检测时，才会进入下一层进行更详细的检测。\n",
    "\n",
    "### 训练过程\n",
    "1. 收集正负样本：收集包含目标对象（如人脸）的正样本和不包含目标对象的负样本。\n",
    "2. 计算LBP特征：对样本图像计算LBP特征。\n",
    "3. 训练弱分类器：使用AdaBoost算法训练多个弱分类器，每个弱分类器基于一个LBP特征。\n",
    "4. 构建级联分类器：将多个弱分类器按层次结构组合成一个级联分类器。\n",
    "\n",
    "### 使用方法\n",
    "在OpenCV中，可以使用CascadeClassifier类加载预训练的LBP级联分类器，并使用DetectMultiScale方法进行人脸检测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var cascade = new CascadeClassifier(\"assets/lbpcascade_frontalface.xml\");\n",
    "using (var src = new Mat(\"assets/faces.jpg\", ImreadModes.Color))\n",
    "using (var gray = new Mat())\n",
    "{\n",
    "    Mat result = src.Clone();\n",
    "    Cv2.CvtColor(src, gray, ColorConversionCodes.BGR2GRAY);\n",
    "\n",
    "    // Detect faces\n",
    "    Rect[] faces = cascade.DetectMultiScale(gray, 1.08, 2, HaarDetectionTypes.ScaleImage, new Size(30, 30));\n",
    "\n",
    "    // Render all detected faces\n",
    "    foreach (Rect face in faces)\n",
    "    {\n",
    "        var center = new Point\n",
    "        {\n",
    "            X = (int)(face.X + face.Width * 0.5),\n",
    "            Y = (int)(face.Y + face.Height * 0.5)\n",
    "        };\n",
    "        var axes = new Size\n",
    "        {\n",
    "            Width = (int)(face.Width * 0.5),\n",
    "            Height = (int)(face.Height * 0.5)\n",
    "        };\n",
    "        Cv2.Ellipse(result, center, axes, 0, 0, 360, new Scalar(255, 0, 255), 4);\n",
    "    }\n",
    "\n",
    "    Cv2.ImShow(\"Faces by Haar\", result);\n",
    "    Cv2.WaitKey(0);\n",
    "    Cv2.DestroyAllWindows();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN（深度神经网络）\n",
    "\n",
    "### 基本概念\n",
    "DNN（深度神经网络）是一种人工神经网络，具有多个隐藏层。DNN在图像分类、目标检测和语音识别等任务中表现出色。常见的DNN架构包括卷积神经网络（CNN）、循环神经网络（RNN）和生成对抗网络（GAN）。\n",
    "\n",
    "### 卷积神经网络（CNN）\n",
    "CNN是一种专门用于处理图像数据的神经网络。它通过卷积层、池化层和全连接层来提取图像特征。卷积层使用卷积核对图像进行卷积操作，池化层对卷积结果进行下采样，全连接层将特征映射到输出类别。\n",
    "\n",
    "### 训练过程\n",
    "1.\t数据准备：收集并标注大量的训练数据。\n",
    "2.\t网络初始化：初始化网络参数，如权重和偏置。\n",
    "3.\t前向传播：将输入数据通过网络，计算输出。\n",
    "4.\t损失计算：计算预测输出与真实标签之间的损失。\n",
    "5.\t反向传播：计算损失相对于网络参数的梯度。\n",
    "6.\t参数更新：使用优化算法（如SGD、Adam）更新网络参数。\n",
    "7.\t迭代训练：重复前向传播、损失计算、反向传播和参数更新，直到损失收敛。\n",
    "\n",
    "### 使用方法\n",
    "在OpenCV中，可以使用dnn模块加载预训练的DNN模型，并使用forward方法进行前向传播，获取检测结果。\n",
    "\n",
    "TODO: 第9行会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "OpenCvSharp.OpenCVException: !blobs.empty() || inputs.size() > 1\r\n   at OpenCvSharp.Internal.NativeMethods.<>c.<.cctor>b__1687_0(ErrorCode status, String funcName, String errMsg, String fileName, Int32 line, IntPtr userData)\r\n   at OpenCvSharp.Internal.NativeMethods.dnn_Net_forward1(IntPtr net, String outputName, IntPtr& returnValue)\r\n   at OpenCvSharp.Dnn.Net.Forward(String outputName)\r\n   at Submission#12.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "OpenCvSharp.OpenCVException: !blobs.empty() || inputs.size() > 1\r\n",
      "   at OpenCvSharp.Internal.NativeMethods.<>c.<.cctor>b__1687_0(ErrorCode status, String funcName, String errMsg, String fileName, Int32 line, IntPtr userData)\r\n",
      "   at OpenCvSharp.Internal.NativeMethods.dnn_Net_forward1(IntPtr net, String outputName, IntPtr& returnValue)\r\n",
      "   at OpenCvSharp.Dnn.Net.Forward(String outputName)\r\n",
      "   at Submission#12.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "using OpenCvSharp.Dnn;\n",
    "\n",
    "var frame = Cv2.ImRead(\"assets/faces.jpg\");\n",
    "int frameHeight = frame.Rows;\n",
    "int frameWidth = frame.Cols;\n",
    "var faceNet = CvDnn.ReadNetFromCaffe(\"assets/bvlc_googlenet.prototxt\", \"assets/res10_300x300_ssd_iter_140000_fp16.caffemodel\");\n",
    "var blob = CvDnn.BlobFromImage(frame, 1.0, new Size(1507, 776), new Scalar(104, 117, 123), false, false);\n",
    "faceNet.SetInput(blob, \"data\");\n",
    "var detection = faceNet.Forward(\"detection_out\");\n",
    "var detectionMat = Mat.FromPixelData(detection.Size(2), detection.Size(3), MatType.CV_32F, detection.Ptr(0));\n",
    "for (int i = 0; i < detectionMat.Rows; i++)\n",
    "{\n",
    "    float confidence = detectionMat.At<float>(i, 2);\n",
    "\n",
    "    if (confidence > 0.7)\n",
    "    {\n",
    "        int x1 = (int)(detectionMat.At<float>(i, 3) * frameWidth);\n",
    "        int y1 = (int)(detectionMat.At<float>(i, 4) * frameHeight);\n",
    "        int x2 = (int)(detectionMat.At<float>(i, 5) * frameWidth);\n",
    "        int y2 = (int)(detectionMat.At<float>(i, 6) * frameHeight);\n",
    "\n",
    "        Cv2.Rectangle(frame, new Point(x1, y1), new Point(x2, y2), new Scalar(0, 255, 0), 2, LineTypes.Link4);\n",
    "    }\n",
    "}\n",
    "\n",
    "Cv2.ImShow(\"Detected Faces\", frame);\n",
    "Cv2.WaitKey(0);\n",
    "Cv2.DestroyAllWindows();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "csharp"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
